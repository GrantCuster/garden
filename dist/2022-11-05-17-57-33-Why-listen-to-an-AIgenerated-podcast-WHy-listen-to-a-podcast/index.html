<html class="bg-hard0 text-foreground">
  <head>
    <title>
      Saturday &middot; Nov 5, 2022 &middot; 5:57 PM - Grant's Garden
    </title>
    <meta
      name="description"
      content="# Why listen to an AI-generated podcast? WHy listen to a podcast?"
    />
    <meta
      property="og:title"
      content="Saturday &middot; Nov 5, 2022 &middot; 5:57 PM - Grant's Garden"
    />
    <meta
      property="og:description"
      content="# Why listen to an AI-generated podcast? WHy listen to a podcast?"
    />
    <meta
      property="og:image"
      content="https://grant-uploader.s3.amazonaws.com/og-images/2022-11-05-17-57-33-Why-listen-to-an-AIgenerated-podcast-WHy-listen-to-a-podcast.png"
    />
    <meta property="twitter:card" content="summary_large_image" />
    <meta
      property="twitter:image"
      content="https://grant-uploader.s3.amazonaws.com/og-images/2022-11-05-17-57-33-Why-listen-to-an-AIgenerated-podcast-WHy-listen-to-a-podcast.png"
    />
    <script src="/index.js"></script>

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="/index.css" />
  </head>
  <body>
    <div class="max-w-[55ch] mx-auto">
      <div class="text-green mt-4 mb-2 px-4">
        <a href="/">Grant's garden</a>
      </div>
      <div class="px-4 text-sm text-dark4 mb-2">
        Saturday &middot; Nov 5, 2022 &middot; 5:57 PM
      </div>
      <div class="px-4 border border-dark1 mb-4 post">
        <div class="markdown">
          <h1
            id="why-listen-to-an-ai-generated-podcast-why-listen-to-a-podcast"
          >
            Why listen to an AI-generated podcast? WHy listen to a podcast?
          </h1>
          <p>
            The new wave of generative text models is impressive. It's also an
            opportunity to think about the purpose of reading (or listening to)
            information. Can generative models satisfy what I want from these
            activities? What do I want, really?
          </p>
          <h2 id="why-listen-to-an-interview">Why listen to an interview</h2>
          <p>
            I like interviews. I like reading and listening to interviews with
            authors or thinkers I like. When I listen, I think I'm generally
            looking for ways to understand their ideas better. If I've read
            their writing, then I've probably heard the distilled version of the
            argument. The cleanest and the best they could come up with. That's
            great, but sometimes it can be so clean it's hard to find a way in.
            Informal interviews, clumsier and with more digressions, can provide
            another way in, the messiness can be welcoming. It also helps remind
            me the author is a person, lessening the gulf between us. We're all
            just people trying to figure things out I think, there's comfort and
            closeness in that for me.
          </p>
          <h2 id="why-ai-generated-interviews-are-probably-not-interesting">
            Why AI-generated interviews are probably not interesting
          </h2>
          <p>
            An example generated interview is
            <a href="https://podcast.ai/"
              >Joe Rogan interviewing Steve Jobs by podast.ai</a
            >. It's mostly plausible to me on both an information and voice
            level. Is it interesting in content, though? I don't think so. The
            model is trained on past Steve Jobs communications, so I know what
            I'm hearing is mostly just a remix of things he said (and that I
            could read or listen to) elsewhere.
          </p>
          <h2 id="whats-the-difference">What's the difference</h2>
          <p>
            Aren't most actual podcast interviews functionally similar remixes,
            though? Reiterations of points already made elsewhere. I think so.
            But something feels different, and I think figuring out what the
            difference is might be the most interesting thing to do here.
          </p>
          <p>
            I think what I'm really trying to do when I listen to an interview
            is understand the interviewee's mental model of the subject
            (possibly of the world). Not just the info they're sharing, but an
            idea of how they processed info to get to that point. I almost
            imagine this as a puzzle where you're gradually filling in pieces:
            some of the pieces are directly related to the main content, some of
            them are seemingly random but somehow revealing asides. It may be
            you have most of the pieces filled in from reading their work, but
            interviews may be how you get some of the less central pieces, that
            get cut from their writing.
          </p>
          <p>
            I'm much less confident I'm going to get those puzzle pieces from
            generated interviews. Generated views are only going to be retreads.
            There's some nuance here -- it's possible the generated interview
            hits upon a rephrase that sparks an understanding in me I wouldn't
            have gotten from the original material. That feels possible but
            unlikely to me. The bigger claim would be that the models are
            actually assembling or approximating the person's mental model, and
            so they can reveral more of it through generation. I don't feel like
            they're there yet, I don't know if they ever will be.
          </p>
          <p>
            Generated interviews also miss out (probably) on the specificity of
            an interview happening at a certain time and place. In real
            interviews you might get a sense of what they're like when they're
            having a bad day or a great one. You might also be able to trace the
            evolution or rejection of their ideas from different periods. My
            guess is that current models are grab-bagging from material across
            time-periods and moods.
          </p>
        </div>
      </div>
    </div>
  </body>
</html>
