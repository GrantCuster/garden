<html class="bg-hard0 text-foreground">
  <head>
    <title>
      Wednesday &middot; Oct 9, 2024 &middot; 9:45 AM - Grant's Garden
    </title>
    <meta name="description" content="# Masks" />
    <meta
      property="og:title"
      content="Wednesday &middot; Oct 9, 2024 &middot; 9:45 AM - Grant's Garden"
    />
    <meta property="og:description" content="# Masks" />
    <meta
      property="og:image"
      content="https://grant-uploader.s3.amazonaws.com/og-images/2024-10-09-09-45-25-Masks.png"
    />
    <meta property="twitter:card" content="summary_large_image" />
    <meta
      property="twitter:image"
      content="https://grant-uploader.s3.amazonaws.com/og-images/2024-10-09-09-45-25-Masks.png"
    />
    <script src="/index.js"></script>

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="/index.css" />
  </head>
  <body>
    <div class="max-w-[55ch] mx-auto">
      <div class="text-green mt-4 mb-2 px-4">
        <a href="/">Grant's garden</a>
      </div>
      <div class="px-4 text-sm text-dark4 mb-2">
        Wednesday &middot; Oct 9, 2024 &middot; 9:45 AM
      </div>
      <div class="px-4 border border-dark1 mb-4 post">
        <div class="markdown">
          <h1 id="masks">Masks</h1>
          <figure>
            <img
              src="https://grant-uploader.s3.amazonaws.com/2024-10-09-19-20-23.gif"
              alt="Me recording my face using masks"
            />
            <figcaption aria-hidden="true">
              Me recording my face using masks
            </figcaption>
          </figure>
          <p>
            <a href="https://masks.constraint.systems">Masks</a> - Collage faces
            using your webcam.
          </p>
          <h2 id="dev-notes">Dev notes</h2>
          <p>
            <a href="https://github.com/constraint-systems/masks"
              >Github repo</a
            >
          </p>
          <h3 id="mediapipe">Mediapipe</h3>
          <p>
            I've been looking at the
            <a
              href="https://mediapipe-studio.webapps.google.com/studio/demo/image_segmenter"
              >mediapipe</a
            >
            set of models for a while. They're small AI models that can run
            on-device (in JavaScript in this case). I was curious how well the
            segmenter could do at background removal. The best model turned out
            to be Mutli-class selfie segmenter 256, which segments hair, face,
            body and clothes separately.
          </p>
          <p>
            I think I was first alerted to Mediapipe possibilities based on
            demos posted by
            <a href="https://x.com/itseieio/status/1805001036941135912"
              >eieio</a
            >
            and
            <a href="https://x.com/kotsoft/status/1820578583749992526"
              >Grant Kot</a
            >.
          </p>
          <h3 id="solitaire-win-state">Solitaire win state</h3>
          <figure>
            <img
              src="https://grant-uploader.s3.amazonaws.com/2024-10-09-19-36-34-800.jpg"
              alt="Winning solitaire"
            />
            <figcaption aria-hidden="true">Winning solitaire</figcaption>
          </figure>
          <p>
            For a long time I've been looking for an excuse to do something with
            the "solitaire win state" effect where a card is drawn on top of
            itself slightly offset. This is the default state of drawing to a
            canvas if you don't clear it, and I'm always interested in using
            default states in interesting ways.
          </p>
          <p>
            I tried this out with drawing the face and was pleased to see if you
            draw only the face segment on top of each other it looks like a
            worm.
          </p>
          <h3 id="performance">Performance</h3>
          <p>
            The Mediapipe models run fast on the GPU. Segmentation was fine at
            60 fps on a Macbook Pro. It struggled more on my Intel LG Gram. For
            segmentation, the results come back as pixel arrays, with a
            different value for each category. (There's also confidence masks
            which would maybe let me have smoother edges, but I didn't dip into
            them for this project.) The [ default example ] shows looping
            through the pixel array to draw depending on your category and then
            you composite the video on top. It's pretty fast but I wondered if
            WebGL could be faster.
          </p>
          <p>
            WebGL worked! Pretty much completely thanks to
            <a
              href="https://github.com/google-ai-edge/mediapipe/issues/5064#issuecomment-1891050563"
              >this issue comment</a
            >
            and
            <a href="https://codepen.io/mediapipe-preview/pen/vYrWvNg"
              >accompanying codepen</a
            >
            from user. The codepen needed import syntax change, and then to be
            <a href="https://codepen.io/GrantCuster/pen/LYwZRvQ"
              >modified for what I was using</a
            >, but it had the foundations of the WebGL approach laid out. I
            didn't rigorously record performance stats, but I think on my Gram
            it went from ~50ms to under 16ms with the switch to WebGL. It will
            still make my fan go, and later I added an FPS throttle to help with
            that. (Plus with this drawing effect a lower FPS is often kind of
            interesting.)
          </p>
          <p>
            I fiddled with the compositing to get fewer draw calls - I'm still a
            little confused about why the blend mode combo results in what it
            does here, but it works.
          </p>
          <p>
            Once I got the WebGL setup things were pretty smooth. I had to
            adjust to a fuzzy category val match for phones - an issue with
            float precision probably?
          </p>
          <p>
            WebGL handles masking out the video using the segmentation. The
            result is drawn to a conventional 2D canvas. This doesn't seem to
            eat up too much performance and it makes things like saving a copy
            or backing it up to local storage simple.
          </p>
          <h3 id="ai-considerations">AI Considerations</h3>
          <p>
            I've been unsure about how to work AI into the Constraint Systems
            stuff. I think these capabilities should be explored, but I didn't
            want to have people pasting in their API keys. With Mediapipe
            everything runs on the user's device, and this experiment should
            continue to work as long as browsers do.
          </p>
          <p>
            I also kind of like the shape of these small models, they have a
            targeted capability and then it's up to you to think of how it can
            be applied - that's the general shape of experimentation I like to
            do.
          </p>
          <p>
            In some ways this is a companion to some of the other image
            manipulation apps I've done, like
            <a href="https://res.constraint.systems">Res</a>, which explored
            pixelation based on compression size. Here we have an algorithm that
            instead pattern matches on faces. We explore and get a feel from the
            capability by experimenting with it. Face tracking can of course be
            put to creepy/bad uses. I think by keeping data here local I can use
            this as a demonstration/education, but it's rocky terrain all
            around. Please don't point it at anybody without their consent. It
            is interesting that even though taking a full video of people around
            you contains the same information (actually more), capturing just
            the faces feels creepier.
          </p>
          <h3 id="long-form-collage">Long form collage</h3>
          <p>
            One thing I like about the 'draw on top of what's there' rendering
            approach is that it can build up and accumulate over time. I'm
            interested in setting up a long running version of this with a
            dedicated screen, that could potentially build up over months.
            Because the web app saves and restores from local storage you also
            get some of this effect from opening on the same device over time.
          </p>
        </div>
      </div>
    </div>
  </body>
</html>
