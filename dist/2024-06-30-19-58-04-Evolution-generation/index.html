<html class="bg-hard0 text-foreground">
  <head>
    <title>
      Sunday &middot; Jun 30, 2024 &middot; 7:58 PM - Grant's Garden
    </title>
    <meta name="description" content="# Evolution generation" />
    <meta
      property="og:title"
      content="Sunday &middot; Jun 30, 2024 &middot; 7:58 PM - Grant's Garden"
    />
    <meta property="og:description" content="# Evolution generation" />
    <meta
      property="og:image"
      content="https://grant-uploader.s3.amazonaws.com/og-images/2024-06-30-19-58-04-Evolution-generation.png"
    />
    <meta property="twitter:card" content="summary_large_image" />
    <meta
      property="twitter:image"
      content="https://grant-uploader.s3.amazonaws.com/og-images/2024-06-30-19-58-04-Evolution-generation.png"
    />
    <script src="/index.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="/index.css" />
  </head>
  <body>
    <div class="max-w-[55ch] mx-auto">
      <div class="text-green mt-4 mb-2 px-4">
        <a href="/">Grant's garden</a>
      </div>
      <div class="px-4 text-sm text-dark4 mb-2">
        Sunday &middot; Jun 30, 2024 &middot; 7:58 PM
      </div>
      <div class="px-4 border border-dark1 mb-4 post">
        <div class="markdown">
          <h1 id="evolution-generation">Evolution generation</h1>
          <p>
            A lot of us are trying to figure out how to use LLMs as a creative
            tool. I'm interested in thinking more about approaches that focus on
            evolution - mutation and selection. There's a set of projects
            related to creative coding, that I've been interesting in thinking
            about more deeply.
          </p>
          <h2 id="serenedipitylm">SerenedipityLM</h2>
          <p>
            <a href="https://x.com/samim">Samin</a> recenterly detailed their
            project
            <a href="https://samim.io/studio/work/serendipityLM/"
              >SerendipityLM</a
            >
            that focuses on "interactive evolutionary exploration of generative
            design models". It features a selection of generative art, mainly
            shader examples, generated through their process.
          </p>
          <p>
            It highlights picbreeder. A non-AI image generation app, where users
            effectively went on a branching scavenger hunt through the
            possibility space. The
            <a
              href="https://wiki.santafe.edu/images/3/34/Stanley_innovation_workshop14.pdf"
              >linked slides write-up</a
            >
            is interesting.
          </p>
          <p>
            The process is admirably clear. It starts with a prompt. Experiments
            are generated and then ranked and critiqued by the user. Those
            ranking are used to generate new exxamples in an interative process.
          </p>
          <h2 id="spellburst">Spellburst</h2>
          <p>
            <a href="https://spellburstllm.github.io/">Spellburst</a> is a paper
            and video demo made by
            <a href="https://x.com/tylerangert">Tyler</a> and collaborators.
            It'd been a while since I'd looked at Spellburst and I think it
            really gets a lot of things right in terms of accomodating different
            levels of control for different parts of the process.
          </p>
          <p>
            There's: - prompts: for starting out and trying out conceptual
            changes in the creative code sketches. This is nice because these
            are often the changes that are tedious to try out quickly in code -
            parameter tweaking: a dat.gui-like interface for tweaking experiment
            parameters. Sometimes you do want to tweak values specifically and
            interactively, and input elements like sliders are definitely a
            better interface for this than a prompt - editing code: for real
            fine-tuned changes there's no substitute for direct code editing.
          </p>
          <p>
            All of this is laid out in a node and wire interface that easily
            allows multiple versions and branches.
          </p>
          <h2 id="clicksynth-and-river">Clicksynth and River</h2>
          <p>
            <a href="https://clicksynth.com">Clicksynth</a> by Max Bittker lets
            you click through generated shaders to explore themes. Clicking into
            one gives you additive themes to add.
          </p>
          <p>
            <a href="https://maxbittker.com/river-notes">River</a> is similar,
            but focused on exploring a dataset. Clicking an image sends you into
            a space of similar images. The sound effects are very satisfying.
          </p>
          <h2 id="what-do-i-think">What do I think?</h2>
          <p>
            These are some of the best examples of interfaces for LLMs as
            creative tools. I think the actually most useful thing for me to do
            is to investigate what I see as the things I still feel are missing.
            To come in another post.
          </p>
        </div>
      </div>
    </div>
  </body>
</html>
