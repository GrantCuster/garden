<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[Grant's Garden]]></title>
        <description><![CDATA[Work and writing in progress]]></description>
        <link>https://garden.grantcuster.com</link>
        <image>
            <url>https://grant-uploader.s3.amazonaws.com/og-images/index.png</url>
            <title>Grant&apos;s Garden</title>
            <link>https://garden.grantcuster.com</link>
        </image>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 13 Sep 2024 01:33:00 GMT</lastBuildDate>
        <atom:link href="https://garden.grantcuster.com/rss.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Fri, 13 Sep 2024 01:33:00 GMT</pubDate>
        <managingEditor><![CDATA[Grant Custer]]></managingEditor>
        <item>
            <title><![CDATA[2024-09-12-21-21-40]]></title>
            <description><![CDATA[Inspired by dynamicland to try some real world manipulation linked to digital objects. I'd guessed coarse color matching would be enough here - it may not be.

![Red construction paper in real life moves sloth on computer](https://grant-uploader.s3.amazonaws.com/2024-09-12-21-22-59.gif)
]]></description>
            <link>https://garden.grantcuster.com/2024-09-12-21-21-40</link>
            <guid isPermaLink="true">https://garden.grantcuster.com/2024-09-12-21-21-40</guid>
            <pubDate>Thu, 12 Sep 2024 21:21:40 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[2024-09-05-17-26-43-Wysywig-brainstorm]]></title>
            <description><![CDATA[# Wysywig brainstorm

Demo that has some promise where all data is in the image file. Sources on the left, canvas layout on the top right. Data encoded as image pixels on the bottom right.

But I'm not excited to jump back into it lately so I need to figure something out.

I think it gets more interesting when I have the three ways of working with the images.

- The first way is like they're... images, the destination has them as movable, resizable boxes.
- The second way is like text. You have keybindings that print the image, and move you to the next square. One undecide piece here is are their text blocks? That complicates things, right? For their to be text blocks - maybe simplifies some things too, maybe they work kind of like they did in Sprout. Expanding out horizontally at first, to some max width then moving down. What is that data structure? Each char belongs to the text block... But that could also help explain why text gets laid out differently. It's not text that does, it's anything in this block. It's a layout in a block yea...
- The third way is paint, makes most sense with colors you could click and drag to print the same image... I guess like chars, a big part of the paint being useful is it should be able to break out of the box clumps - that's why you use it for something like annotation on top of other pieces. Maybe you group it together as you paint - i've done that before too.

But then it's more like a conventional image editor app. Maybe that's fine. I"ve tried to avoid layers before, hmmm...
]]></description>
            <link>https://garden.grantcuster.com/2024-09-05-17-26-43-Wysywig-brainstorm</link>
            <guid isPermaLink="true">https://garden.grantcuster.com/2024-09-05-17-26-43-Wysywig-brainstorm</guid>
            <pubDate>Thu, 05 Sep 2024 17:26:43 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[2024-09-05-17-13-52-Hand-landmark-ideas]]></title>
            <description><![CDATA[# Hand landmark ideas

Brainstorming on the train. Laying out the pieces.

I can use mediapipe hand landmark. I know the positions of the fingers. I'll use pointer finger as cursor, if they have two hands up I can use both of them...

I can use pointer and thumb pincer as click. I can normalize distance based on lower knuckle thumb distance probably. Click and drag works with that motion too, although maybe it's a shame you can't just point and drag - maybe also some ability to toggle based on the other hand.

You could also try and distinguish point and drag from fist, so that raising one finger was the trigger - interesting you'd want to wait until it was fully raised though, probably need a little delay.

Idea to use your hand to 'freeze pixels' in a webcam just by dragging across an area... Question of when your fingers are 'live' and active.

Pixelate pixels by clicking, every click doubles the pixel area. That would actually work I think. I donder if I even grid it out in that case or just do it iteratively over the top... I think do it over the top but bigger pixels would overwrite smaller pixels. You'd want to set up pointerDown, pointerMove, pointerUp events, which would be fun in it's own right. And I guess you'd always track pointer as pointer... I think I'd need to chunk it up a bit though, because there's got to be some instability just sitting that there's not with a mouse or trackpad.

Maybe that's a good first demo. Pointerdown, pointermove, pointerup. What do you do when a hand goes offscreen? I think you keep it down if it's down huh? Till it comes back not down.

A bummer with webcam examples is I won't be able to write them on the train.
]]></description>
            <link>https://garden.grantcuster.com/2024-09-05-17-13-52-Hand-landmark-ideas</link>
            <guid isPermaLink="true">https://garden.grantcuster.com/2024-09-05-17-13-52-Hand-landmark-ideas</guid>
            <pubDate>Thu, 05 Sep 2024 17:13:52 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[2024-09-03-09-37-47-Cyberdeck-glasses-edition]]></title>
            <description><![CDATA[# Cyberdeck: glasses edition

![The elements: mini PC, AR glasses, portable battery, bluetooth keyboard](https://grant-uploader.s3.amazonaws.com/2024-09-03-16-21-02-2000.jpg)

![Simulation of POV from the porch. A floating window over the world.](https://grant-uploader.s3.amazonaws.com/2024-09-03-16-21-46-2000.jpg)

After trying out a [DIY deck version](/2024-04-22-20-46-52/), I've redone my cyberdeck experiment using AR glasses. It's not perfect but I've been using it pretty consistently on subway commutes and porch nights.

## Parts list

The parts list - very much inspired by the [Cyberdeck subreddit](https://www.reddit.com/r/cyberDeck/)

- Melee mini PC, Intel N100, 8gb RAM - [amazon link](https://www.amazon.com/dp/B0CP3WV82R)
- Xreal air 2 pro AR glasses - [link](https://us.shop.xreal.com/products/xreal-air-2-pro)
- INIU 45w charger - [link](https://www.amazon.com/dp/B09GJQG5S3?ref_=pe_386300_442618370_TE_sc_as_ri_0)
- Technikable bluetooth keyboard - [link](https://www.boardsource.xyz/products/Technikable)

The big plus of the mini PC is it has a powered display port out that can run the glasses, and another usb-c in for the battery (or laptop charger) power.

Most of the time this all gets transported in Bellroy cross-body bag.

- Bellroy bag

![Contents in the bag](https://grant-uploader.s3.amazonaws.com/2024-09-03-16-22-25-2000.jpg)

This is an iteration of when I had a keyboard plugging into my iPhone. The [exposed keyboard had a look](https://garden.grantcuster.com/2024-03-11-00-36-36/), but is probably not good for long term durability.

## Software

For software it runs the same thing I've been running everywhere these days. Ubuntu server with most things managed using Nix home-manager. Sway for a window manager. It is great to have things in sync with my Linux laptop, and close to sync (through home-manager) with the Mac I use at work.

## Visibility

I run the glasses in monitor mode, so there's no eye-tracking or anything. The compatibility has been great (can plug and unplug just like any other monitor). Readability can be tough, especially when looking at corners. I have the display scaled up to 2x which basically solves readability at the cost of information density. Sway helps here, it feels great to have basically no system chrome in the way.

![Simulation screenshot, close to what it looks like in practice](https://grant-uploader.s3.amazonaws.com/2024-09-03-16-21-46-2000.jpg)

The glasses work well in shade and rooms. In bright sunlight one of the biggest challenges is actually reflection up from your chest/shirt. The glasses cover helps a lot with this, it'd be cool to have a version that didn't also block out all light. A good candidate for 3D printing maybe.

## The keyboard

The keyboard is kind of its own whole deal, if you're doing this set up and aren't already deep in ergo keyboard world (see [ErgoMech subreddit](https://www.reddit.com/r/ErgoMechKeyboards/)), just get a conventional bluetooth keyboard + trackpad combo. That said the keyboard (using the [miryoku layout](https://github.com/manna-harbour/miryoku)) is a lot of fun as a lap keyboard, and the mouse keys feature is good in a pinch. 

Bluetooth has been the biggest hiccup, though. Sometimes the connection is choppy, with lots of latency. I don't know enough to know if it's the keyboard broadcaster, the mini PC bluetooth receiver, the bluetooth software, or some combo. Will continue investigating that. If I'm having lots of trouble and going to be sat for a while I just plug it in and use as a USB keyboard since that works to.

## Uses

### Subway

So far I mostly use it on the subway to noodle on side projects or write things like this post. I have about 45 minutes on the train, so it's great to be able to use that time I'd otherwise probably dedicate to podcasts. I've sometimes pulled out a laptop on the subway, this is less obtrusive but probably looks weirder - still I hope it's mostly an enjoyable cyberpunk-ish curiosity for the other riders. No one has said anything to me about it yet.

### Porch

I've also been using it on the porch, especially when trying to do some writing after the baby's gone to bed. This works OK - it's pretty with the neighborhood visible in the background, but I also feel like I'm pushing myself to use it there. Part of using it is really appreciating the laptop form factor - the extra screen space (because not scaled), the ability to look at different parts of the screen without it following you around... I wouldn't be surprised if I shift back to that more. The glasses setup really shines for the portability. But it's also a matter of getting the kinks/friction out, it's possible if I get my software set up just the right way I'll reach for the glasses more.

### TV

![](https://grant-uploader.s3.amazonaws.com/2024-09-03-16-23-14-2000.jpg)

This doesn't involve the glasses but I realized I can plug the mini PC into the TV, it's kind of nice for an almost ambient coding experience, where I can drop in, change a few lines, then walk away and straighten something up. Maybe there's some fit with the [Ambient TV](https://garden.grantcuster.com/2024-08-19-18-17-26/) setup there.

### Monitor

It also works as a regular PC, I wasn't expecting to use it much this way, but it's nice if I'm in the process of working on something and need a change of scenery. The combined display port means it plugs right into a one-cord laptop dock.

The mini PC is so small it's almost like plugging in a cartridge. I wonder if there's some fun/interesting setup with multiple task-specific mini PCs you swap out.

### Entertainment

I haven't pursued it much but I also want to have things set up to watch videos, particularly on subway rides where I don't get a seat. MPV and the media controls on bluetooth headphones should get me most of the way I think.

## Do I recommend it 

The challenge with any of this homebrew deck stuff is it's going to have sharp edges. If you really want to do this it's doable, but it definitely has a time cost. I hope to continue to iterate and make things smoother - paving the way for more alternative setups.
]]></description>
            <link>https://garden.grantcuster.com/2024-09-03-09-37-47-Cyberdeck-glasses-edition</link>
            <guid isPermaLink="true">https://garden.grantcuster.com/2024-09-03-09-37-47-Cyberdeck-glasses-edition</guid>
            <pubDate>Tue, 03 Sep 2024 09:37:47 GMT</pubDate>
        </item>
    </channel>
</rss>